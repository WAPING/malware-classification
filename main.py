#!/usr/bin/env python 3.6
# -*- coding: utf-8 -*-
# @File  : main.py
# @Author: wang anping
# @Date  : 2018/11/7
# @Desc  : 
# @Contact : 15236759872@163.com
# @Software : PyCharm
"""
main program implementing the deep learning algorithms
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
from model.cnn_svm import CNN
from model.rnn_svm import RNNSVm
import numpy as np
from sklearn.model_selection import train_test_split
from utils.data import load_data
from utils.data import one_hot_encode

BATCH_SIZE = 256
CELL_SIZE = 256
DROPOUT_RATE = 0.85
LEARNING_RATE = 1e-3
NODE_SIZE = [512, 256, 128]
NUM_LAYERS = 5


def parse_args():
    parser = argparse.ArgumentParser(
        description='Deep Learning Using Support Vector Machine for Malware Classification'
    )
    group = parser.add_argument_group('Arguments')
    group.add_argument('-m', '--model', required=True, type=int, help='[1] CNN-SVM,[2] RNN-SVM')
    group.add_argument('-d', '--dataset', required=True, type=str,
                       help='the dataset to be used')
    group.add_argument('-n', '--num_epochs', required=True, type=int,
                       help='number of epochs')
    group.add_argument('-c', '--penalty_parameter', required=True, type=float,
                       help='the SVM C penalty parameter')
    group.add_argument('-k', '--checkpoint_path', required=True, type=str,
                       help='path where to save the trained model')
    group.add_argument('-l', '--log_path', required=True, type=str,
                       help='path where to save the TensorBoard logs')
    group.add_argument('-r', '--result_path', required=True, type=str,
                       help='path where to save actual and predicted labels array')
    arguments = parser.parse_args()

    return arguments


def main(arguments):
    model_choice = arguments.model
    assert model_choice == 1 or model_choice == 2, 'Invalid choice: Choose among 1,2 only'

    dataset = np.load(arguments.dataset)
    features, labels = load_data(dataset=dataset)
    labels = one_hot_encode(labels=labels)

    # get the features dimension
    num_features = features.shape[1]
    # get the classes' dimension
    num_classes = labels.shape[1]

    # split the dataset by 70/30
    # 数据集的划分，之前未使用random_state 来限定进行每一次训练过程的 每一次使用的相同的训练集和测试集
    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.30,
                                                                                stratify=labels)

    train_size = int(train_features.shape[0])
    train_features = train_features[:train_size - (train_size % BATCH_SIZE)]
    train_labels = train_labels[:train_size - (train_size % BATCH_SIZE)]

    test_size = int(test_features.shape[0])
    test_features = test_features[:test_size - (test_size % BATCH_SIZE)]
    test_labels = test_labels[:test_size - (test_size % BATCH_SIZE)]

    # train the model
    if model_choice == 1:  # cnn with svm
        model = CNN(alpha=LEARNING_RATE, batch_size=BATCH_SIZE, num_classes=num_classes,
                    num_features=num_features, penalty_parameter=arguments.penalty_parameter)
        model.train(checkpoint_path=arguments.checkpoint_path, log_path=arguments.log_path,
                    result_path=arguments.result_path, epochs=arguments.num_epochs,
                    train_data=[train_features, train_labels], train_size=int(train_features.shape[0]),
                    test_data=[test_features, test_labels], test_size=int(test_features.shape[0]))
    elif model_choice == 2:  # attention-based gru with svm
        train_features = np.reshape(train_features, (train_features.shape[0],
                                                     int(np.sqrt(train_features.shape[1])),
                                                     int(np.sqrt(train_features.shape[1]))))
        test_features = np.reshape(test_features, (test_features.shape[0],
                                                   int(np.sqrt(test_features.shape[1])),
                                                   int(np.sqrt(test_features.shape[1]))))
        model = RNNSVm(alpha=LEARNING_RATE, batch_size=BATCH_SIZE, cell_size=CELL_SIZE, dropout_rate=DROPOUT_RATE,
                       num_classes=num_classes, num_layers=NUM_LAYERS, sequence_height=train_features.shape[2],
                       sequence_width=train_features.shape[1], svm_c=arguments.penalty_parameter)
        model.train(checkpoint_path=arguments.checkpoint_path, log_path=arguments.log_path, epochs=arguments.num_epochs,
                    train_data=[train_features, train_labels], train_size=int(train_features.shape[0]),
                    test_data=[test_features, test_labels], test_size=int(test_features.shape[0]),
                    result_path=arguments.result_path
                    )


if __name__ == '__main__':
    arguments = parse_args()

    main(arguments)
