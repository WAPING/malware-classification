#!/usr/bin/env python 3.6
# -*- coding: utf-8 -*-
# @File  : classifier.py
# @Author: wang anping
# @Date  : 2018/11/10
# @Desc  : 
# @Contact : 15236759872@163.com
# @Software : PyCharm
"""
Modele for classifier based on a trained DL_SVM model
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import numpy as np
import os
import tensorflow as tf
from utils.data import load_data
from utils.data import one_hot_encode

BATCH_SIZE = 'batch_size'
CELL_SIZE = 'cell_size'


def predict(dataset, model_path, **kwargs):
    """return classification result of the input test data
    
    :param dataset: the dataset to be classified using the trained model
    :param model_path: the path where the trained cnn-svn model is saved
    :param kwargs: 
    :return: 
    """

    init_op = tf.group(tf.local_variables_initializer(), tf.global_variables_initializer())

    # accuracy_tensor_name = 'accuracy/accuracy/Mean:0'
    # prediction_tensor_name = 'accuracy/predicted_class:0'

    assert BATCH_SIZE in kwargs, 'KeyNotFound : {}'.format(BATCH_SIZE)
    assert type(kwargs[BATCH_SIZE]) is int, \
        'Expected data type : int ,but {} is {}'.format(kwargs[BATCH_SIZE], type(kwargs[BATCH_SIZE]))

    feed_dict = {'x_input:0': None, 'y_input:0': None, 'p_keep:0': 1.0}

    accuracy_tensor_name = 'metrics/accuracy/Mean:0'
    prediction_tensor_name = 'metrics/predicted_class:0'

    predictions_array = np.array([])
    accuracy_array = np.array([])

    with tf.Session() as sess:
        sess.run(init_op)

        checkpoint = tf.train.get_checkpoint_state(model_path)
        if checkpoint and checkpoint.model_checkpoint_path:
            saver = tf.train.import_meta_graph(checkpoint.model_checkpoint_path + '.meta')

            saver.restore(sess, tf.train.latest_checkpoint(model_path))
            print('Loaded trained model from {} '.format(tf.train.latest_checkpoint(model_path)))

        assert 'size' in kwargs, 'KeyNotFound : {}'.format('size')

        try:
            for step in range(kwargs['size'] // kwargs['batch_size']):
                offset = (step * kwargs['batch_size']) % kwargs['size']
                features = dataset[0][offset:(offset + kwargs['batch_size'])]
                labels = dataset[1][offset:(offset + kwargs['batch_size'])]

                feed_dict['x_input:0'] = features
                feed_dict['y_input:0'] = labels

                prediction_tensor = sess.graph.get_tensor_by_name(prediction_tensor_name)
                predictions = sess.run(prediction_tensor, feed_dict=feed_dict)

                predictions_array = np.append(predictions_array, predictions)

                accuracy_tensor = sess.graph.get_tensor_by_name(accuracy_tensor_name)
                accuracy = sess.run(accuracy_tensor, feed_dict=feed_dict)

                accuracy_array = np.append(accuracy_array, accuracy)
        except KeyboardInterrupt:
            print('KeyboardInterrupt at step {}'.format(step))

    return predictions_array, accuracy_array


def parse_args():
    parser = argparse.ArgumentParser(
        description='Deep learning using support vector machine for malware classification'
    )
    group = parser.add_argument_group('Arguments')
    group.add_argument('-t', '--model_path', required=True, type=str,
                       help='path where to save the trained model')
    group.add_argument('-d', '--dataset', required=True, type=str,
                       help='the dataset to be classified')
    arguments = parser.parse_args()

    return arguments


def main(arguments):
    model_path = arguments.model_path
    dataset_path = arguments.dataset

    assert os.path.exists(path=model_path), '{} does not exists!'.format(model_path)
    assert os.path.exists(path=dataset_path), '{} does not exists!'.format(dataset_path)

    dataset = np.load(dataset_path)
    features, labels = load_data(dataset=dataset)
    labels = one_hot_encode(labels=labels)

    dataset_size = features.shape[0]
    print(features.shape)

    predictions, accuracies = predict(dataset=[features, labels], model_path=model_path, size=dataset_size,
                                      batch_size=256)

    print('predictions: {}'.format(predictions))
    print('Accuracies: {}'.format(accuracies))
    print('Avrage accuracy : {}'.format(np.mean(accuracies)))


if __name__ == '__main__':
    arguments = parse_args()

    main(arguments=arguments)
