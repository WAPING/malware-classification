from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

__version__ = "0.1.0"
__author__ = "WAPING"

import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import StandardScaler
import tensorflow as tf


def save_labels(predictions, actual, result_path, phase, step):
    """saves the actual and prediction labels to a NPY
    
    :param predictions: The NumPy array containing the predicted labels.
    :param actual: the NumPy array containing the actual labels.
    :param result_path: The path where to save the concatenated actual and predicted labels.
    :param phase: The phase for which the predictions is, i.e. training/validation/testing.
    :param step: The time step for the NumPy arrays.
    :return: 
    """
    if not os.path.exists(result_path):
        os.mkdir(result_path)

    labels = np.concatenate((predictions, actual), axis=1) # 连接在同一行

    np.save(file=os.path.join(result_path, '{}-{}.npy'.format(phase, step)), arr=labels)


def load_data(dataset, standardize=True):
    """ 从数据集中获取实验使用的数据
    
    :param dataset: 
    :param standardize: 
    :return: 
    """

    features = dataset['arr'][:, 0]
    features = np.array([feature for feature in features])
    features = np.reshape(features, (features.shape[0], features.shape[1] * features[2]))

    if standardize:
        # 标准化数据，保证每个维度的特征数据方差为1，均值为0，使得预测结果不会被某些维度过大的特征值而主导 ,fit_transform()先拟合数据，再标准化
        features = StandardScaler().fit_transform(features)

    labels = dataset['arr'][:, 1]
    labels = np.array([label for label in labels])

    return features, labels


def one_hot_encode(labels):
    """ 将所属的分类表示为 one-hot向量的形式，维度为 恶意代码种类数+1 （1 stand for 良性代码类）
    
    :param labels: 
    :return: 
    """
    one_hot = np.zeros((labels.shape[0], labels.max() + 1))
    one_hot[np.arange(labels.shape[0]), labels] = 1
    labels = one_hot
    labels[labels == 0] = -1
    return labels

def plot_confusion_matrix(phase,path,class_names):
    """ 绘制confusion 矩阵
    
    :param phase: str
     String value indicating for what phase is the confusion matrix ,i.e. training/validation/testing
    :param path: str 
     Dictionary where the predicted and actual label NPY files reside
    :param class_names: List of the class names for the labels
    :return: 
    --------
    conf: array ,shape=[num_classes,num_classes]
      Confusion matrix
    accuracy: float 
     Predictive accuracy
    """

    files=list_files(path=path)

    labels=np.array([])

    for file in files:
        labels_batch=np.load(file)
        labels=np.append(labels,labels_batch)

        if (files.index(file)/files.__len__())% 0.2 ==0:
            print("Done appending {}% of {}".format((files.index(file)/files.__len__())*100,files.__len__()))
    labels=np.reshape(labels,newshape=(labels.shape[0]//50,50))
    print("Done appending NPY files")

    predictions=labels[:,:25]
    actual=labels[:,25:]

    with tf.Session() as sess:
        predictions=sess.run(tf.argmax(predictions,1))
        actual=sess.run(tf.argmax(actual,1))

    conf=confusion_matrix(y_true=actual,y_pred=predictions)

    report=classification_report(y_true=actual,y_pred=predictions,target_names=class_names)
    #TODO: 完成该函数

def list_files(path):
    #TODO 完成该函数
    return "test"












